{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating sentiments for article titles using our finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env WANDB_DISABLED=true\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "!pip install datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    model = 'finbert-finetune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/MyDrive/FYP/processed_proquest_articles_with_dates.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/extracted_data')  # Extract to a folder named 'extracted_data'\n",
    "\n",
    "# 2. Read the CSV file and print the first 5 lines\n",
    "csv_file_path = '/content/extracted_data/processed_proquest_articles_with_dates.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Extract the zip file\n",
    "data_path = '/content/drive/MyDrive/FYP/processed_proquest_articles_with_dates.csv.zip'\n",
    "with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/extracted_data')  # Extract to a folder named 'extracted_data'\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file_path = '/content/extracted_data/processed_proquest_articles_with_dates.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_columns = [\"Company\", \"Date\", \"Title\", \"Content\"]\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    raise ValueError(f\"The dataset must contain the following columns: {required_columns}\")\n",
    "\n",
    "# Load the FinBERT model and tokenizer\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Combine Title and Content\n",
    "df['Title_Content'] = df['Title'] + \" \" + df['Content']\n",
    "\n",
    "# Process each combined text and calculate sentiment\n",
    "all_texts = df[\"Title_Content\"].tolist()\n",
    "all_companies = df[\"Company\"].tolist()\n",
    "all_dates = df[\"Date\"].tolist()\n",
    "\n",
    "# Store the results in lists\n",
    "sentiments = []\n",
    "sentiment_scores = []\n",
    "\n",
    "# Loop through combined text for prediction\n",
    "for i, text in enumerate(tqdm(all_texts, desc=\"Processing articles\")):\n",
    "    # Tokenize text\n",
    "    tokenized_text = tokenizer(\n",
    "        text,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        # Get model outputs (exclude invalid keys)\n",
    "        inputs = {k: v.to(device) for k, v in tokenized_text.items() if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "\n",
    "        # Get sentiment label and score\n",
    "        sentiment_idx = np.argmax(probabilities)\n",
    "        sentiment_label = [\"negative\", \"neutral\", \"positive\"][sentiment_idx]\n",
    "\n",
    "        sentiment_score = probabilities[sentiment_idx]\n",
    "        if sentiment_label == \"negative\":\n",
    "            sentiment_score = -sentiment_score  # Make negative for negative sentiment\n",
    "\n",
    "        # Append results\n",
    "        sentiments.append(sentiment_label)\n",
    "        sentiment_scores.append(sentiment_score)\n",
    "\n",
    "# Create a DataFrame to hold the results\n",
    "rdf = pd.DataFrame({\n",
    "    \"Company\": all_companies,\n",
    "    \"Date\": all_dates,\n",
    "    \"text\": all_texts,\n",
    "    \"sentiment\": sentiments,\n",
    "    \"sentiment_score\": sentiment_scores\n",
    "})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(rdf.head())\n",
    "\n",
    "# Optional: Save the DataFrame to a CSV file\n",
    "output_file_path = '/content/drive/MyDrive/FYP/sentiment_results_title_content.csv'\n",
    "rdf.to_csv(output_file_path, index=False)\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
